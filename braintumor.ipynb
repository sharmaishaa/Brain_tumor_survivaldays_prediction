{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmaishaa/Brain_tumor_survivaldays_prediction/blob/main/braintumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3lP29aQUFrN",
        "outputId": "dbbeb06e-dfeb-4542-bb9a-1ce424648978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "TF version: 2.19.0\n",
            "GPU available: []\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 - setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, random, math, glob, h5py, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_absolute_error\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Paths - change if needed\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/data\"  # where your .h5 files are\n",
        "CSV_PATH = \"/content\"  # where your name_mapping.csv, meta_data.csv, survival_info.csv are uploaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CR9p5qijVXzv",
        "outputId": "a6c7138c-d555-421f-c68a-969b7a9f8918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for CSVs at:\n",
            "/content/drive/MyDrive/data/name_mapping.csv\n",
            "/content/drive/MyDrive/data/meta_data.csv\n",
            "/content/drive/MyDrive/data/survival_info.csv\n",
            "Loaded CSV shapes:\n",
            "name_mapping.csv -> (369, 6)\n",
            "meta_data.csv -> (57195, 4)\n",
            "survival_info.csv -> (236, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Grade BraTS_2017_subject_ID BraTS_2018_subject_ID TCGA_TCIA_subject_ID  \\\n",
              "0   HGG   Brats17_CBICA_AAB_1   Brats18_CBICA_AAB_1                  NaN   \n",
              "1   HGG   Brats17_CBICA_AAG_1   Brats18_CBICA_AAG_1                  NaN   \n",
              "2   HGG   Brats17_CBICA_AAL_1   Brats18_CBICA_AAL_1                  NaN   \n",
              "3   HGG   Brats17_CBICA_AAP_1   Brats18_CBICA_AAP_1                  NaN   \n",
              "4   HGG   Brats17_CBICA_ABB_1   Brats18_CBICA_ABB_1                  NaN   \n",
              "\n",
              "  BraTS_2019_subject_ID BraTS_2020_subject_ID  \n",
              "0   BraTS19_CBICA_AAB_1  BraTS20_Training_001  \n",
              "1   BraTS19_CBICA_AAG_1  BraTS20_Training_002  \n",
              "2   BraTS19_CBICA_AAL_1  BraTS20_Training_003  \n",
              "3   BraTS19_CBICA_AAP_1  BraTS20_Training_004  \n",
              "4   BraTS19_CBICA_ABB_1  BraTS20_Training_005  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f11f02c-50b6-4ec0-9dae-c76b1eaae82e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>BraTS_2017_subject_ID</th>\n",
              "      <th>BraTS_2018_subject_ID</th>\n",
              "      <th>TCGA_TCIA_subject_ID</th>\n",
              "      <th>BraTS_2019_subject_ID</th>\n",
              "      <th>BraTS_2020_subject_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HGG</td>\n",
              "      <td>Brats17_CBICA_AAB_1</td>\n",
              "      <td>Brats18_CBICA_AAB_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BraTS19_CBICA_AAB_1</td>\n",
              "      <td>BraTS20_Training_001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HGG</td>\n",
              "      <td>Brats17_CBICA_AAG_1</td>\n",
              "      <td>Brats18_CBICA_AAG_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BraTS19_CBICA_AAG_1</td>\n",
              "      <td>BraTS20_Training_002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HGG</td>\n",
              "      <td>Brats17_CBICA_AAL_1</td>\n",
              "      <td>Brats18_CBICA_AAL_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BraTS19_CBICA_AAL_1</td>\n",
              "      <td>BraTS20_Training_003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HGG</td>\n",
              "      <td>Brats17_CBICA_AAP_1</td>\n",
              "      <td>Brats18_CBICA_AAP_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BraTS19_CBICA_AAP_1</td>\n",
              "      <td>BraTS20_Training_004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HGG</td>\n",
              "      <td>Brats17_CBICA_ABB_1</td>\n",
              "      <td>Brats18_CBICA_ABB_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BraTS19_CBICA_ABB_1</td>\n",
              "      <td>BraTS20_Training_005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f11f02c-50b6-4ec0-9dae-c76b1eaae82e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f11f02c-50b6-4ec0-9dae-c76b1eaae82e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f11f02c-50b6-4ec0-9dae-c76b1eaae82e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b489c8ee-5a7e-4b4e-ac2e-d168251e091f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b489c8ee-5a7e-4b4e-ac2e-d168251e091f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b489c8ee-5a7e-4b4e-ac2e-d168251e091f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              Brats20ID     Age Survival_days Extent_of_Resection\n",
              "0  BraTS20_Training_001  60.463           289                 GTR\n",
              "1  BraTS20_Training_002  52.263           616                 GTR\n",
              "2  BraTS20_Training_003  54.301           464                 GTR\n",
              "3  BraTS20_Training_004  39.068           788                 GTR\n",
              "4  BraTS20_Training_005  68.493           465                 GTR"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978d3b59-f81a-4a10-9eac-c61da155d201\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brats20ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Survival_days</th>\n",
              "      <th>Extent_of_Resection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BraTS20_Training_001</td>\n",
              "      <td>60.463</td>\n",
              "      <td>289</td>\n",
              "      <td>GTR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BraTS20_Training_002</td>\n",
              "      <td>52.263</td>\n",
              "      <td>616</td>\n",
              "      <td>GTR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BraTS20_Training_003</td>\n",
              "      <td>54.301</td>\n",
              "      <td>464</td>\n",
              "      <td>GTR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BraTS20_Training_004</td>\n",
              "      <td>39.068</td>\n",
              "      <td>788</td>\n",
              "      <td>GTR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BraTS20_Training_005</td>\n",
              "      <td>68.493</td>\n",
              "      <td>465</td>\n",
              "      <td>GTR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978d3b59-f81a-4a10-9eac-c61da155d201')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-978d3b59-f81a-4a10-9eac-c61da155d201 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-978d3b59-f81a-4a10-9eac-c61da155d201');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b2862d3-11b7-4c28-bf09-9ccac97a7f2b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b2862d3-11b7-4c28-bf09-9ccac97a7f2b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b2862d3-11b7-4c28-bf09-9ccac97a7f2b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Tumor Grade Mapping Loaded:\\\", len(patient_to_grade))\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Brats20ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"BraTS20_Training_002\",\n          \"BraTS20_Training_005\",\n          \"BraTS20_Training_003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.8820938150707,\n        \"min\": 39.068,\n        \"max\": 68.493,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          52.263,\n          68.493,\n          54.301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survival_days\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"616\",\n          \"465\",\n          \"464\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extent_of_Resection\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GTR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Outlier Removal for Survival Days ---\n",
            "Original entries with survival info: 236\n",
            "Q1: 190.00, Q3: 579.25, IQR: 389.25\n",
            "Lower bound: -393.88, Upper bound: 1163.12\n",
            "Entries after outlier removal: 221\n",
            "\n",
            "--- Debugging patient_id and survival_days in temp before mapping ---\n",
            "temp['patient_id'] head:\n",
            " 0    001\n",
            "1    002\n",
            "2    003\n",
            "3    004\n",
            "4    005\n",
            "Name: patient_id, dtype: object\n",
            "temp['patient_id'] null count: 0\n",
            "temp['survival_days'] head:\n",
            " 0    289\n",
            "1    616\n",
            "2    464\n",
            "3    788\n",
            "4    465\n",
            "Name: survival_days, dtype: int64\n",
            "temp['survival_days'] null count: 0\n",
            "Total rows in temp: 221\n",
            "Survival Mapping Loaded: 221\n",
            "Tumor Grade Mapping Loaded: 369\n"
          ]
        }
      ],
      "source": [
        "# CELL 2 – Load CSVs from Drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re # Import re for regex operations\n",
        "\n",
        "CSV_PATH = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "map_path = os.path.join(CSV_PATH, \"name_mapping.csv\")\n",
        "meta_path = os.path.join(CSV_PATH, \"meta_data.csv\")\n",
        "surv_path = os.path.join(CSV_PATH, \"survival_info.csv\")\n",
        "\n",
        "print(\"Looking for CSVs at:\")\n",
        "print(map_path)\n",
        "print(meta_path)\n",
        "print(surv_path)\n",
        "\n",
        "# load CSVs\n",
        "df_map = pd.read_csv(map_path) if os.path.exists(map_path) else pd.DataFrame()\n",
        "df_meta = pd.read_csv(meta_path) if os.path.exists(meta_path) else pd.DataFrame()\n",
        "df_surv = pd.read_csv(surv_path) if os.path.exists(surv_path) else pd.DataFrame()\n",
        "\n",
        "print(\"Loaded CSV shapes:\")\n",
        "print(\"name_mapping.csv ->\", df_map.shape)\n",
        "print(\"meta_data.csv ->\", df_meta.shape)\n",
        "print(\"survival_info.csv ->\", df_surv.shape)\n",
        "\n",
        "if not df_map.empty:\n",
        "    display(df_map.head())\n",
        "if not df_surv.empty:\n",
        "    display(df_surv.head())\n",
        "\n",
        "# -----------------------------\n",
        "#  BUILD PATIENT → SURVIVAL DAYS MAP\n",
        "# -----------------------------\n",
        "\n",
        "patient_to_surv = {}\n",
        "\n",
        "if not df_surv.empty and 'Brats20ID' in df_surv.columns:\n",
        "\n",
        "    temp = df_surv.copy()\n",
        "\n",
        "    # Extract numeric patient id (last digits from Brats20ID), pad 3 digits (001, 045, etc.)\n",
        "    # Example: 'BraTS20_Training_001' -> '001'\n",
        "    temp[\"patient_id\"] = (\n",
        "        temp[\"Brats20ID\"]\n",
        "        .astype(str)\n",
        "        .str.extract(r\"(\\d+)$\") # Extract digits at the end\n",
        "        [0] # Get the first (and only) capturing group\n",
        "        .fillna('') # Replace NaN with empty string to prevent zfill from failing\n",
        "        .apply(lambda x: x.zfill(3) if x else None) # Pad to 3 digits, or None if empty\n",
        "    )\n",
        "\n",
        "    # clean survival days\n",
        "    if \"Survival_days\" in temp.columns:\n",
        "        temp[\"survival_days\"] = (\n",
        "            temp[\"Survival_days\"]\n",
        "            .astype(str)\n",
        "            .str.extract(r\"(\\d+)\")[0]\n",
        "        )\n",
        "        temp[\"survival_days\"] = pd.to_numeric(temp[\"survival_days\"], errors=\"coerce\")\n",
        "    else:\n",
        "        temp[\"survival_days\"] = np.nan\n",
        "\n",
        "    # -----------------------------\n",
        "    #  OUTLIER REMOVAL FOR SURVIVAL DAYS (re-added section)\n",
        "    # -----------------------------\n",
        "    print(\"\\n--- Outlier Removal for Survival Days ---\")\n",
        "    initial_rows_surv = temp.shape[0]\n",
        "\n",
        "    # Filter out NaNs for outlier calculation\n",
        "    numeric_survival_days = temp['survival_days'].dropna()\n",
        "\n",
        "    if not numeric_survival_days.empty:\n",
        "        Q1 = numeric_survival_days.quantile(0.25)\n",
        "        Q3 = numeric_survival_days.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Filter out outliers from temp DataFrame\n",
        "        # Keep NaNs as they are not outliers in the numeric sense and will be handled by mapping\n",
        "        temp = temp[(temp['survival_days'] >= lower_bound) | temp['survival_days'].isna()]\n",
        "        temp = temp[(temp['survival_days'] <= upper_bound) | temp['survival_days'].isna()]\n",
        "\n",
        "        print(f\"Original entries with survival info: {initial_rows_surv}\")\n",
        "        print(f\"Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
        "        print(f\"Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
        "        print(f\"Entries after outlier removal: {temp.shape[0]}\")\n",
        "    else:\n",
        "        print(\"No numeric survival days found to perform outlier removal.\")\n",
        "\n",
        "    # -----------------------------\n",
        "    #  END OUTLIER REMOVAL SECTION\n",
        "    # -----------------------------\n",
        "\n",
        "    # Debugging prints for patient_id and survival_days before mapping\n",
        "    print(\"\\n--- Debugging patient_id and survival_days in temp before mapping ---\")\n",
        "    print(\"temp['patient_id'] head:\\n\", temp['patient_id'].head())\n",
        "    print(\"temp['patient_id'] null count:\", temp['patient_id'].isnull().sum())\n",
        "    print(\"temp['survival_days'] head:\\n\", temp['survival_days'].head())\n",
        "    print(\"temp['survival_days'] null count:\", temp['survival_days'].isnull().sum())\n",
        "    print(\"Total rows in temp:\", temp.shape[0])\n",
        "\n",
        "    # finalize mapping\n",
        "    for _, row in temp.iterrows():\n",
        "        pid = row[\"patient_id\"]\n",
        "        # Ensure pid is a valid numeric string before using as key\n",
        "        if pd.notnull(pid):\n",
        "            patient_to_surv[pid] = (\n",
        "                row[\"survival_days\"] if not pd.isna(row[\"survival_days\"]) else None\n",
        "            )\n",
        "\n",
        "print(\"Survival Mapping Loaded:\", len(patient_to_surv))\n",
        "\n",
        "# -----------------------------\n",
        "#  BUILD PATIENT → GRADE MAP  (Tumor Present = Yes/No)\n",
        "# -----------------------------\n",
        "\n",
        "patient_to_grade = {}\n",
        "\n",
        "if not df_map.empty:\n",
        "\n",
        "    # find ID column\n",
        "    id_col = None\n",
        "    for opt in [\"BraTS_2020_subject_ID\", \"Subject_ID\", \"ID\", \"brats_id\"]:\n",
        "        if opt in df_map.columns:\n",
        "            id_col = opt\n",
        "            break\n",
        "    if id_col is None:\n",
        "        id_col = df_map.columns[0]   # fallback\n",
        "\n",
        "    # find grade / tumor-type column\n",
        "    grade_col = None\n",
        "    for opt in [\"Grade\", \"grade\", \"TumorType\", \"tumor_type\"]:\n",
        "        if opt in df_map.columns:\n",
        "            grade_col = opt\n",
        "            break\n",
        "\n",
        "    # build mapping\n",
        "    if id_col is not None and grade_col is not None:\n",
        "        for _, rr in df_map.iterrows():\n",
        "            full_pid = str(rr[id_col])\n",
        "            # Extract 3-digit numeric part from full_pid for consistency\n",
        "            match = re.search(r\"(\\d+)$\", full_pid)\n",
        "            if match:\n",
        "                pid = match.group(1).zfill(3) # Ensure 3-digit like '001'\n",
        "            else:\n",
        "                pid = None # Or handle cases where ID is not found / not numeric\n",
        "            grade = rr[grade_col]\n",
        "\n",
        "            if pid is not None and pd.notnull(grade):\n",
        "                patient_to_grade[pid] = str(grade).strip()\n",
        "\n",
        "print(\"Tumor Grade Mapping Loaded:\", len(patient_to_grade))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7zZoT1TRVX2h"
      },
      "outputs": [],
      "source": [
        "# Cell 3 - helper functions\n",
        "\n",
        "def get_volume_from_h5(path):\n",
        "    \"\"\"\n",
        "    Attempts to read an h5 file and return (volume, mask).\n",
        "    volume -> numpy array shape (S, H, W)\n",
        "    mask -> same shape or None if not available\n",
        "    \"\"\"\n",
        "    with h5py.File(path, 'r') as f:\n",
        "        # Heuristics: common keys in BRaTS .h5: 'image', 'vol', 'data'; mask: 'mask', 'segmentation'\n",
        "        vol = None\n",
        "        msk = None\n",
        "        for key in f.keys():\n",
        "            k_low = key.lower()\n",
        "            if k_low in ('image', 'images', 'vol', 'volume', 'data', 't1', 't1ce', 'flair'):\n",
        "                try:\n",
        "                    arr = np.array(f[key])\n",
        "                    if arr.ndim == 3:\n",
        "                        vol = arr\n",
        "                        break\n",
        "                except:\n",
        "                    pass\n",
        "        # If not found yet, pick first 3D dataset\n",
        "        if vol is None:\n",
        "            for key in f.keys():\n",
        "                try:\n",
        "                    arr = np.array(f[key])\n",
        "                    if arr.ndim == 3:\n",
        "                        vol = arr\n",
        "                        break\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        # find mask-like dataset\n",
        "        for key in f.keys():\n",
        "            k_low = key.lower()\n",
        "            if k_low in ('mask', 'seg', 'segmentation', 'label'):\n",
        "                try:\n",
        "                    arr = np.array(f[key])\n",
        "                    if arr.ndim == 3:\n",
        "                        msk = arr\n",
        "                        break\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    # Standardize orientation: assume vol is (S,H,W) or (H,W,S)\n",
        "    if vol is None:\n",
        "        raise ValueError(f\"No 3D dataset found in {path}\")\n",
        "    vol = vol.astype(np.float32)\n",
        "    # If the last dim is smallest, could be (H,W,S)\n",
        "    if vol.shape[2] < vol.shape[0] and vol.shape[2] < vol.shape[1]:\n",
        "        vol = np.transpose(vol, (2,0,1))\n",
        "    if msk is not None:\n",
        "        msk = msk.astype(np.uint8)\n",
        "        if msk.shape != vol.shape:\n",
        "            # try transpose\n",
        "            if msk.shape[2] < msk.shape[0] and msk.shape[2] < msk.shape[1]:\n",
        "                msk = np.transpose(msk, (2,0,1))\n",
        "    return vol, msk\n",
        "\n",
        "def normalize_slice(slice2d):\n",
        "    mn = slice2d.min()\n",
        "    mx = slice2d.max()\n",
        "    if mx - mn < 1e-8:\n",
        "        return np.zeros_like(slice2d, dtype=np.float32)\n",
        "    out = (slice2d - mn) / (mx - mn)\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "def file_patient_id_from_name(fname):\n",
        "    \"\"\"Try to extract a 3-digit patient id from filename or Brats20ID portion.\"\"\"\n",
        "    bn = os.path.basename(fname)\n",
        "    # Try to match 'volume_XXX_slice_YYY' format\n",
        "    match = re.search(r\"volume_(\\d+)_\", bn)\n",
        "    if match:\n",
        "        return match.group(1).zfill(3) # Extract number and pad to 3 digits\n",
        "    # If not matched, try to match 'Brats20_Training_XXX' or similar if present in filename\n",
        "    match = re.search(r\"(\\d+)$\", os.path.splitext(bn)[0])\n",
        "    if match:\n",
        "        return match.group(1).zfill(3) # Extract number and pad to 3 digits\n",
        "    # Fallback if no numeric ID found\n",
        "    return os.path.splitext(bn)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNLXBcnwVX5l",
        "outputId": "ab9f1161-5576-4b11-90f1-56f1a030a16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total .h5 files in data folder: 32422\n",
            "Blocks: 649, BLOCK_SIZE=50, pick 10 per block\n",
            "Selected volumes count: 6490\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/data/volume_100_slice_134.h5',\n",
              " '/content/drive/MyDrive/data/volume_100_slice_104.h5',\n",
              " '/content/drive/MyDrive/data/volume_100_slice_1.h5',\n",
              " '/content/drive/MyDrive/data/volume_100_slice_113.h5',\n",
              " '/content/drive/MyDrive/data/volume_100_slice_111.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "# Cell 4 - discover .h5 files and prepare sampling blocks\n",
        "all_h5 = sorted([os.path.join(DRIVE_DATA_PATH, f) for f in os.listdir(DRIVE_DATA_PATH) if f.endswith('.h5')])\n",
        "print(\"Total .h5 files in data folder:\", len(all_h5))\n",
        "if len(all_h5) == 0:\n",
        "    raise SystemExit(\"No .h5 files found in DRIVE_DATA_PATH. Check the path or upload files.\")\n",
        "\n",
        "# We'll partition the file list into blocks of 50 (1-50, 51-100...) and from each block sample up to N_VOLUMES_PER_BLOCK volumes\n",
        "BLOCK_SIZE = 50\n",
        "N_VOLUMES_PER_BLOCK = 10   # from each block of 50 volumes, pick 10 volumes randomly\n",
        "MAX_BLOCKS = math.ceil(len(all_h5) / BLOCK_SIZE)\n",
        "print(f\"Blocks: {MAX_BLOCKS}, BLOCK_SIZE={BLOCK_SIZE}, pick {N_VOLUMES_PER_BLOCK} per block\")\n",
        "\n",
        "selected_volume_paths = []\n",
        "for b in range(MAX_BLOCKS):\n",
        "    start = b * BLOCK_SIZE\n",
        "    end = min((b + 1) * BLOCK_SIZE, len(all_h5))\n",
        "    block_files = all_h5[start:end]\n",
        "    pick = min(N_VOLUMES_PER_BLOCK, len(block_files))\n",
        "    sampled = random.sample(block_files, pick)\n",
        "    selected_volume_paths.extend(sampled)\n",
        "\n",
        "print(\"Selected volumes count:\", len(selected_volume_paths))\n",
        "# show example\n",
        "selected_volume_paths[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3_2Ajz6VX8O",
        "outputId": "ed44dede-d2d8-45f8-eef3-3978e8151de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing samples from selected volumes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 2008/6490 [10:22<01:56, 38.44it/s]"
          ]
        }
      ],
      "source": [
        "# Cell 5 - create dataset (small)\n",
        "# For each selected volume, pick up to N_SLICES_PER_VOL random slices to represent the volume\n",
        "N_SLICES_PER_VOL = 10            # number of slices to sample per selected volume\n",
        "TARGET_HW = (128, 128)           # resize slices to this spatial size\n",
        "CHANNELS = 3                     # stack to RGB-like for CNN\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "import cv2\n",
        "\n",
        "def prepare_volume_sample(h5_path, n_slices=N_SLICES_PER_VOL, target_hw=TARGET_HW):\n",
        "    vol, mask = get_volume_from_h5(h5_path)    # vol shape (S,H,W)\n",
        "    S = vol.shape[0]\n",
        "    # choose slice indices: if S < n_slices then sample with replacement or pad later\n",
        "    if S <= n_slices:\n",
        "        idxs = list(range(S))\n",
        "    else:\n",
        "        idxs = random.sample(list(range(S)), n_slices)\n",
        "\n",
        "    slices = []\n",
        "    mask_presence = 0\n",
        "    for i in idxs:\n",
        "        sl = vol[i]\n",
        "        sln = normalize_slice(sl)\n",
        "        # resize to target_hw\n",
        "        slr = cv2.resize(sln, (target_hw[1], target_hw[0]), interpolation=cv2.INTER_AREA)\n",
        "        # convert single channel to CHANNELS (RGB style)\n",
        "        if CHANNELS == 3:\n",
        "            sl_rgb = np.stack([slr, slr, slr], axis=-1)\n",
        "        else:\n",
        "            sl_rgb = slr[...,None]\n",
        "        slices.append(sl_rgb.astype(np.float32))\n",
        "        # check mask presence for that slice\n",
        "        if mask is not None:\n",
        "            if mask.shape[0] == vol.shape[0]:\n",
        "                if np.sum(mask[i]) > 50:\n",
        "                    mask_presence += 1\n",
        "            else:\n",
        "                # fallback: if shapes mismatched, try to check any nonzero in whole mask\n",
        "                if np.sum(mask) > 0:\n",
        "                    mask_presence = 1\n",
        "\n",
        "    slices = np.stack(slices, axis=0)  # (n_slices, H, W, C)\n",
        "    # decide binary label: tumor present if any selected slice has mask pixels OR if patient mapping says HGG\n",
        "    binary_label = 1 if mask_presence > 0 else 0\n",
        "\n",
        "    # try also to check mapping from file name\n",
        "    pid = file_patient_id_from_name(h5_path)\n",
        "    if pid in patient_to_grade:\n",
        "        g = patient_to_grade[pid]\n",
        "        # treat HGG as tumor present\n",
        "        if g.upper().find('HGG') >= 0:\n",
        "            binary_label = 1\n",
        "        elif g.upper().find('LGG') >= 0:\n",
        "            binary_label = binary_label or 0\n",
        "\n",
        "    # survival days from patient_to_surv mapping if available (else NaN)\n",
        "    surv = patient_to_surv.get(pid, np.nan)\n",
        "\n",
        "    return slices, int(binary_label), surv, pid\n",
        "\n",
        "# Build arrays (volume-level)\n",
        "vol_embeddings_slices = []   # list of (n_slices,H,W,C) arrays per volume\n",
        "labels_binary = []\n",
        "labels_surv = []\n",
        "patient_ids = []\n",
        "paths_used = []\n",
        "\n",
        "print(\"Preparing samples from selected volumes ...\")\n",
        "for pth in tqdm(selected_volume_paths):\n",
        "    try:\n",
        "        sls, lbl, surv, pid = prepare_volume_sample(pth)\n",
        "        vol_embeddings_slices.append(sls)   # keep slices - we will pass through CNN later\n",
        "        labels_binary.append(lbl)\n",
        "        labels_surv.append(surv if not pd.isna(surv) else np.nan)\n",
        "        patient_ids.append(pid)\n",
        "        paths_used.append(pth)\n",
        "    except Exception as e:\n",
        "        print(\"Error reading\", pth, e)\n",
        "\n",
        "print(\"Prepared volumes:\", len(vol_embeddings_slices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBWTR0-gVX-q"
      },
      "outputs": [],
      "source": [
        "# Cell 6 - slice-level CNN encoder -> produces embedding per slice; then average across slices for volume embedding\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "EMBED_DIM = 256\n",
        "\n",
        "def build_slice_encoder(input_shape=(TARGET_HW[0], TARGET_HW[1], CHANNELS), embedding_dim=EMBED_DIM):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inp)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
        "    model = Model(inp, x, name='slice_encoder')\n",
        "    return model\n",
        "\n",
        "slice_encoder = build_slice_encoder()\n",
        "slice_encoder.summary()\n",
        "\n",
        "# Compute embeddings for each slice and average per volume\n",
        "volume_embeddings = []  # shape (n_volumes, EMBED_DIM)\n",
        "valid_indices = []      # keep indices where embedding computed successfully\n",
        "print(\"Computing per-volume embeddings (average of slice embeddings)...\")\n",
        "for i, sls in enumerate(tqdm(vol_embeddings_slices)):\n",
        "    try:\n",
        "        # sls shape (n_slices, H, W, C)\n",
        "        emb_slices = slice_encoder.predict(sls, verbose=0)   # (n_slices, EMBED_DIM)\n",
        "        # average pooling across slices\n",
        "        emb_vol = np.mean(emb_slices, axis=0)\n",
        "        volume_embeddings.append(emb_vol)\n",
        "        valid_indices.append(i)\n",
        "    except Exception as e:\n",
        "        print(\"Failed embedding for volume\", i, \"error:\", e)\n",
        "\n",
        "volume_embeddings = np.stack(volume_embeddings, axis=0).astype(np.float32)\n",
        "labels_binary = np.array(labels_binary)[valid_indices].astype(int)\n",
        "labels_surv = np.array(labels_surv)[valid_indices].astype(np.float32)\n",
        "patient_ids = np.array(patient_ids)[valid_indices]\n",
        "paths_used = np.array(paths_used)[valid_indices]\n",
        "\n",
        "print(\"Final dataset volumes (after embedding):\", volume_embeddings.shape)\n",
        "print(\"Labels (binary) shape:\", labels_binary.shape)\n",
        "print(\"Survival labels shape:\", labels_surv.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYvr6bM-VYBj"
      },
      "outputs": [],
      "source": [
        "# Cell 7 - train/test split at volume-level\n",
        "# We'll keep a regression target for survival if available; for missing survival values, we'll exclude from regression training\n",
        "X = volume_embeddings\n",
        "y_class = labels_binary\n",
        "y_surv_raw = labels_surv  # may contain NaN\n",
        "\n",
        "# Train/test split (stratify by class to keep balance)\n",
        "X_tr, X_te, ytr_class, yte_class, ytr_surv, yte_surv, tr_ids, te_ids, tr_paths, te_paths = train_test_split(\n",
        "    X, y_class, y_surv_raw, patient_ids, paths_used, test_size=0.2, random_state=SEED, stratify=y_class\n",
        ")\n",
        "\n",
        "print(\"Train volumes:\", X_tr.shape[0], \"Test volumes:\", X_te.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v167vN74VYC0"
      },
      "outputs": [],
      "source": [
        "# Cell 8 - multi-head model on top of embeddings\n",
        "IN_DIM = X_tr.shape[1]\n",
        "\n",
        "inp = layers.Input(shape=(IN_DIM,), name='embedding_input')\n",
        "x = layers.Dense(128, activation='relu')(inp)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "# classification head\n",
        "c = layers.Dense(32, activation='relu')(x)\n",
        "c = layers.Dropout(0.2)(c)\n",
        "out_class = layers.Dense(1, activation='sigmoid', name='tumor_present')(c)\n",
        "\n",
        "# regression head (predict log1p of days)\n",
        "r = layers.Dense(32, activation='relu')(x)\n",
        "r = layers.Dropout(0.2)(r)\n",
        "out_reg = layers.Dense(1, activation='linear', name='survival_log')(r)\n",
        "\n",
        "multi_head = models.Model(inputs=inp, outputs=[out_class, out_reg], name='multi_head_model')\n",
        "multi_head.compile(\n",
        "    optimizer=optimizers.Adam(1e-3),\n",
        "    loss={\n",
        "        'tumor_present': losses.BinaryCrossentropy(),\n",
        "        'survival_log': losses.MeanSquaredError()\n",
        "    },\n",
        "    loss_weights={'tumor_present': 1.0, 'survival_log': 0.5},  # downweight regression if noisy\n",
        "    metrics={'tumor_present': ['accuracy'], 'survival_log': ['mae']}\n",
        ")\n",
        "multi_head.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9I1kVu4f9dx"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 9 — TRAINING (with Checkpoints + EarlyStopping)\n",
        "# ============================================================\n",
        "\n",
        "# 1. Create a folder in Drive to store checkpoints\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/model_checkpoints_brats\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"best_model.keras\")\n",
        "\n",
        "# 2. Callbacks\n",
        "early_stopping_callback = callbacks.EarlyStopping(\n",
        "    monitor='val_tumor_present_accuracy', # Corrected output name\n",
        "    patience=5,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    monitor='val_tumor_present_accuracy', # Corrected output name\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3. Prepare targets for training\n",
        "# survival regression has NaN values → mask them out\n",
        "train_mask = ~np.isnan(ytr_surv)\n",
        "test_mask  = ~np.isnan(yte_surv)\n",
        "\n",
        "ytr_surv_clean = np.nan_to_num(ytr_surv, nan=0)\n",
        "yte_surv_clean = np.nan_to_num(yte_surv, nan=0)\n",
        "\n",
        "# 4. Compile the model\n",
        "multi_head.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'tumor_present': 'binary_crossentropy', # Corrected output name\n",
        "        'survival_log': 'mse' # Corrected output name\n",
        "    },\n",
        "    loss_weights={\n",
        "        'tumor_present': 1.0, # Corrected output name\n",
        "        'survival_log': 0.3 # Corrected output name\n",
        "    },\n",
        "    metrics={\n",
        "        'tumor_present': ['accuracy'], # Corrected output name\n",
        "        'survival_log': ['mae'] # Corrected output name\n",
        "    }\n",
        ")\n",
        "\n",
        "# 5. Train the model\n",
        "history = multi_head.fit(\n",
        "    X_tr,\n",
        "    {\n",
        "        'tumor_present': ytr_class, # Corrected output name\n",
        "        'survival_log': ytr_surv_clean # Corrected output name\n",
        "    },\n",
        "    validation_data=(\n",
        "        X_te,\n",
        "        {\n",
        "            'tumor_present': yte_class, # Corrected output name\n",
        "            'survival_log': yte_surv_clean # Corrected output name\n",
        "        }\n",
        "    ),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training Completed!\")\n",
        "print(f\"Best model saved at: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W920TyViGx-F"
      },
      "outputs": [],
      "source": [
        "#cell new1\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Input embedding (256-D vector from slice encoder)\n",
        "inp = Input(shape=(256,))\n",
        "\n",
        "# Shared dense layers\n",
        "x = Dense(128, activation='relu')(inp)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Head 1 – Tumor Classification\n",
        "class_output = Dense(1, activation='sigmoid', name='tumor_output')(x)\n",
        "\n",
        "# Head 2 – Survival Regression\n",
        "reg_output = Dense(1, activation='linear', name='survival_output')(x)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# NEW HEAD 3 – Consistency loss: tumor_prob * survival_days\n",
        "# Forces: high tumor prob → low survival days\n",
        "# ----------------------------------------------------------\n",
        "consistency_output = Lambda(\n",
        "    lambda z: z[0] * z[1],\n",
        "    name='consistency_output'\n",
        ")([class_output, reg_output])\n",
        "\n",
        "# Final Model\n",
        "multi_head = Model(\n",
        "    inputs=inp,\n",
        "    outputs=[class_output, reg_output, consistency_output]\n",
        ")\n",
        "\n",
        "multi_head.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brt919uYGyPI"
      },
      "outputs": [],
      "source": [
        "#new cell 2\n",
        "multi_head.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'tumor_output': 'binary_crossentropy',\n",
        "        'survival_output': 'mse',\n",
        "        'consistency_output': 'mse'\n",
        "    },\n",
        "    loss_weights={\n",
        "        'tumor_output': 1.0,\n",
        "        'survival_output': 1.0,\n",
        "        'consistency_output': 0.3   # small weight but enforces correlation\n",
        "    },\n",
        "    metrics={\n",
        "        'tumor_output': ['accuracy'],\n",
        "        'survival_output': ['mae']\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVV1jbEfVYEK"
      },
      "outputs": [],
      "source": [
        "# Cell 9 - prepare targets for training\n",
        "# For regression training we will only include volumes with known survival days (non-NaN)\n",
        "# create masks\n",
        "def safe_log1p(x):\n",
        "    return np.log1p(x)\n",
        "\n",
        "# create y_surv_train_log only for available values; we'll feed full arrays but set sample_weight=0 for missing rows in regression\n",
        "ytr_surv_arr = np.array([v if not np.isnan(v) else 0.0 for v in ytr_surv], dtype=np.float32)\n",
        "yte_surv_arr = np.array([v if not np.isnan(v) else 0.0 for v in yte_surv], dtype=np.float32)\n",
        "ytr_surv_log = safe_log1p(ytr_surv_arr)\n",
        "yte_surv_log = safe_log1p(yte_surv_arr)\n",
        "\n",
        "# sample weights for regression: 1 if survival known else 0 (so loss doesn't include missing)\n",
        "wtr_reg = np.array([0.0 if np.isnan(v) else 1.0 for v in ytr_surv], dtype=np.float32).reshape(-1, 1)\n",
        "wte_reg = np.array([0.0 if np.isnan(v) else 1.0 for v in yte_surv], dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "# For classification head weights we keep ones\n",
        "wtr_class = np.ones_like(wtr_reg, dtype=np.float32)\n",
        "wte_class = np.ones_like(wte_reg, dtype=np.float32)\n",
        "\n",
        "# For consistency head weights we keep ones (always apply this regularization)\n",
        "wtr_consistency = np.ones_like(wtr_class, dtype=np.float32)\n",
        "wte_consistency = np.ones_like(wte_class, dtype=np.float32)\n",
        "\n",
        "# Combine sample weights into a dict for fit\n",
        "sample_weights_train = {\n",
        "    'tumor_output': wtr_class,\n",
        "    'survival_output': wtr_reg,\n",
        "    'consistency_output': wtr_consistency\n",
        "}\n",
        "sample_weights_val = {\n",
        "    'tumor_output': wte_class,\n",
        "    'survival_output': wte_reg,\n",
        "    'consistency_output': wte_consistency\n",
        "}\n",
        "\n",
        "# Prepare y dicts for fit\n",
        "y_train_dict = {\n",
        "    'tumor_output': ytr_class.reshape(-1,1),\n",
        "    'survival_output': ytr_surv_log.reshape(-1,1),\n",
        "    'consistency_output': np.zeros_like(ytr_class.reshape(-1,1), dtype=np.float32) # Target for consistency: typically 0 to minimize product\n",
        "}\n",
        "y_val_dict   = {\n",
        "    'tumor_output': yte_class.reshape(-1,1),\n",
        "    'survival_output': yte_surv_log.reshape(-1,1),\n",
        "    'consistency_output': np.zeros_like(yte_class.reshape(-1,1), dtype=np.float32)\n",
        "}\n",
        "\n",
        "print(\"Training samples (reg known):\", int(wtr_reg.sum()), \"Validation samples (reg known):\", int(wte_reg.sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHCrfvYJXrgP"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH = 8\n",
        "\n",
        "# --- Checkpoint directory ---\n",
        "checkpoint_dir = os.path.join(DRIVE_DATA_PATH, 'model_checkpoints')\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_filepath = os.path.join(checkpoint_dir, 'multi_head_best.h5')\n",
        "\n",
        "# --- Callback ---\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- TRAINING: EVERYTHING MUST BE A DICT ---\n",
        "history = multi_head.fit(\n",
        "    X_tr,\n",
        "    {\n",
        "        'tumor_output': y_train_tumor,\n",
        "        'survival_output': y_train_survival,\n",
        "        'consistency_output': np.zeros(len(y_train_tumor))\n",
        "    },\n",
        "    validation_data=(\n",
        "        X_te,\n",
        "        {\n",
        "            'tumor_output': y_val_tumor,\n",
        "            'survival_output': y_val_survival,\n",
        "            'consistency_output': np.zeros(len(y_val_tumor))\n",
        "        }\n",
        "    ),\n",
        "    sample_weight={\n",
        "        'tumor_output': np.ones(len(y_train_tumor)),\n",
        "        'survival_output': np.ones(len(y_train_survival)),\n",
        "        'consistency_output': np.ones(len(y_train_tumor))\n",
        "    },\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    verbose=2,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "print(\"Checkpoint saved at:\", checkpoint_filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9dF1w7FHO2U"
      },
      "outputs": [],
      "source": [
        "#new cell3  Add third output → consistency target = zeros\n",
        "y_train_dict = {\n",
        "    'tumor_output': y_train_tumor,\n",
        "    'survival_output': y_train_survival,\n",
        "    'consistency_output': np.zeros(len(y_train_tumor))\n",
        "}\n",
        "\n",
        "y_val_dict = {\n",
        "    'tumor_output': y_val_tumor,\n",
        "    'survival_output': y_val_survival,\n",
        "    'consistency_output': np.zeros(len(y_val_tumor))\n",
        "}\n",
        "\n",
        "# TRAINING\n",
        "history = multi_head.fit(\n",
        "    X_train,\n",
        "    y_train_dict,\n",
        "    validation_data=(X_val, y_val_dict),\n",
        "    epochs=40,\n",
        "    batch_size=8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHi5HNg1XwjS"
      },
      "outputs": [],
      "source": [
        "# Cell 11 - evaluation\n",
        "preds = multi_head.predict(X_te, verbose=0)\n",
        "pred_class_probs = preds[0].reshape(-1)\n",
        "pred_reg_log = preds[1].reshape(-1)\n",
        "\n",
        "pred_class_labels = (pred_class_probs >= 0.5).astype(int)\n",
        "true_class_labels = yte_class.astype(int)\n",
        "\n",
        "# Classification metrics\n",
        "acc = accuracy_score(true_class_labels, pred_class_labels)\n",
        "print(\"Test classification accuracy:\", acc)\n",
        "print(\"\\nClassification report:\\n\", classification_report(true_class_labels, pred_class_labels))\n",
        "\n",
        "cm = confusion_matrix(true_class_labels, pred_class_labels)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Tumor Presence\")\n",
        "plt.show()\n",
        "\n",
        "# Regression metrics: only on entries where ground truth survival exists (wte_reg == 1)\n",
        "mask_reg = (wte_reg == 1).flatten() # Flatten the mask to be 1D\n",
        "if mask_reg.sum() > 0:\n",
        "    true_reg_log = yte_surv_log[mask_reg]\n",
        "    pred_reg_log_masked = pred_reg_log[mask_reg]\n",
        "    # convert back to days\n",
        "    true_days = np.expm1(true_reg_log)\n",
        "    pred_days = np.expm1(pred_reg_log_masked)\n",
        "    mae_days = mean_absolute_error(true_days, pred_days)\n",
        "    print(f\"Regression MAE (days) on {mask_reg.sum()} samples: {mae_days:.2f}\")\n",
        "    # print some examples\n",
        "    print(\"\\nExamples: true_days vs pred_days\")\n",
        "    for t, p, pid in list(zip(true_days, pred_days, te_ids[mask_reg]))[:10]:\n",
        "        print(f\"pid {pid} \\u2192 true {t:.1f}, pred {p:.1f}\")\n",
        "else:\n",
        "    print(\"No survival ground-truth available in test to evaluate regression.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTHPC3PuHMWh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obit7l953MJ-"
      },
      "outputs": [],
      "source": [
        "# Cell 12 - optional save (uncomment to save)\n",
        "# save the slice encoder and multi-head model (SavedModel format) if desired\n",
        "# slice_encoder.save(\"/content/slice_encoder_saved\")\n",
        "# multi_head.save(\"/content/multi_head_saved\")\n",
        "print(\"Models can be saved by uncommenting the save lines in this cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKF0uvBN3MW2"
      },
      "outputs": [],
      "source": [
        "# Cell 13 - prediction function for input .h5 file (user input)\n",
        "def predict_from_h5(h5_path, n_slices=N_SLICES_PER_VOL, target_hw=TARGET_HW):\n",
        "    if not os.path.exists(h5_path):\n",
        "        print(\"File not found:\", h5_path); return None\n",
        "    vol, mask = get_volume_from_h5(h5_path)\n",
        "    S = vol.shape[0]\n",
        "    # choose slices evenly if many slices, else random\n",
        "    if S <= n_slices:\n",
        "        idxs = list(range(S))\n",
        "    else:\n",
        "        # sample evenly spaced indices for reproducibility\n",
        "        idxs = np.linspace(0, S-1, n_slices, dtype=int).tolist()\n",
        "\n",
        "    slices = []\n",
        "    for i in idxs:\n",
        "        sl = normalize_slice(vol[i])\n",
        "        slr = cv2.resize(sl, (target_hw[1], target_hw[0]), interpolation=cv2.INTER_AREA)\n",
        "        if CHANNELS == 3:\n",
        "            sl_rgb = np.stack([slr, slr, slr], axis=-1)\n",
        "        else:\n",
        "            sl_rgb = slr[...,None]\n",
        "        slices.append(sl_rgb.astype(np.float32))\n",
        "    slices = np.stack(slices, axis=0)\n",
        "\n",
        "    # compute slice embeddings\n",
        "    emb_slices = slice_encoder.predict(slices, verbose=0)\n",
        "    emb_vol = np.mean(emb_slices, axis=0).reshape(1, -1)\n",
        "\n",
        "    # multi-head prediction\n",
        "    pred_class_prob, pred_reg_log = multi_head.predict(emb_vol, verbose=0)\n",
        "    tumor_prob = float(pred_class_prob[0][0])\n",
        "    tumor_label = int(tumor_prob >= 0.5)\n",
        "    pred_days = float(np.expm1(pred_reg_log[0][0]))\n",
        "\n",
        "    print(f\"Predicted tumor presence (prob): {tumor_prob:.3f} → label {tumor_label}\")\n",
        "    print(f\"Predicted survival days (expm1 of log): {pred_days:.1f}\")\n",
        "    return {'tumor_prob': tumor_prob, 'tumor_label': tumor_label, 'survival_days': pred_days, 'patient_id': file_patient_id_from_name(h5_path)}\n",
        "\n",
        "# Example usage (uncomment and change path)\n",
        "# res = predict_from_h5(\"/content/drive/MyDrive/data/BraTS20_Training_001.h5\")\n",
        "# print(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba5BuL4U3Sd9"
      },
      "outputs": [],
      "source": [
        "# Cell 14 - interactive input for .h5 path\n",
        "h5_input = input(\"Enter path to a single .h5 file (e.g. /content/drive/MyDrive/data/BraTS20_Training_001.h5): \").strip()\n",
        "if h5_input:\n",
        "    predict_from_h5(h5_input)\n",
        "else:\n",
        "    print(\"No path entered.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPViIkO7LeHmyT0rbP48ogF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}